# ----------------------- #
#      Main Configs       #
# ----------------------- #

url:                http://quantumhack.ml
title:              Quantum Hack
email:              mail@quantumhack.ml
author:             Quantum Hack
description:        Write an awesome description for your new site here.
 Books An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani
 The Elements of Statistical Learning Data Mining, Inference, and Prediction by Trevor Hastie, Robert Tibshirani, and Jerome Friedman
 Fuzzy Sets and Fuzzy Logic Theory and Applications by George J Klir and Bo Yuan Life 3.0 Being Human in the Age of Artificial Intelligence by Max Tegmart
 Machine Learning The New AI by Ethem Alpaydin
 The Master Algorithm How the Quest for the Ultimate Learning Machine Will Remake Our World by Pedro Domingos
 Nexus (The Nexus Trilogy Book 1) by Ramez Naam (this is the only fiction book on the list)
 Nonlinear Dynamics and Chaos With Applications to Physics, Biology, Chemistry, and Engineering by Steven H. Strogatz
 On Intelligence How a New Understanding of the Brain Will Lead to the Creation of Truly Intelligent Machines by Jeff Hawkins and Sandra Blakeslee
 Our Mathematical Universe My Quest for the Ultimate Nature of Reality by Max Tegmart
 Courses
 Applying Machine Learning to your Data with GCP by Google Cloud Training at Coursera
 In depth Introduction to Machine Learning in 15 Hours of Expert Videos by Kevin Markham (2014) at R bloggers or DataSchool.io (this supplementary resource comes highly recommended and includes the slides and videos to a course by the authors of An Introduction to Statistical Learning with Applications in R, above)
 Neural Networks and Deep Learning by Andrew Ng, Kian Katanforoosh, and Younes Bensouda Mourri at Coursera
 Neural Networks for Machine Learning — Geoffrey Hinton 2016, a 78-video playlist by Colin McDonnell at Youtube (the Coursera course itself appears to no longer be available)
 Long Reads
 “Markov Chain Monte Carlo Methods, Rejection Sampling and the Metropolis-Hastings Algorithm” by Brian Keng (2015) at Bounded Rationality
 “Markov Chain Monte Carlo Models, Gibbs Sampling, & Metropolis Algorithm for High-Dimensionality Complex Stochastic Problems” by Yogesh Malhotra (2015) in The SSRN
 “Marvin Minsky’s Vision of the Future” / “A.I.” by Jeremy Bernstein (1981) in The New Yorker
 “Neuralink and the Brain’s Magical Future” by Tim Urban (2017) in Wait But Why
 “Neuroscience-Inspired Artificial Intelligence” by Demis Hassabis, Dharshan Kumaran, Christopher Summerfield, and Matthew Botvinick (2017) in Neuron
 “One Giant Step for a Chess-Playing Machine” by Steven Strogatz (2018) in The New York Times
 “Progress Report on Artificial Intelligence” by Marvin Minsky and Seymour Papert (1971) at MIT
 People
 Pieter Abbeel — Berkeley reinforcement learning researcher
 Francois Chollet — inventor of the Keras neural network library
 Lex Fridman — MIT research scientist and AI podcast host
 Demis Hassabis — co-founder of artificial general intelligence research company DeepMind
 Andrej Karpathy — Tesla’s AI Director with a focus on Autopilot perception
 Fei-Fei Li — Stanford professor and computer vision expert
 Andrew Ng — professor, co-founder of Coursera, & deep learning expert
 Carol Reiley — roboticist and co-founder of autonomous driving company drive.ai
 Daniela Rus — roboticist and Director of MIT’s famed CSAIL laboratory
 Miscellaneous Topics
 How the class of problems you wish to solve impact your choice of learning model, machine learning algorithm, and neural networks
 How the computational expensiveness of certain neural network calculations (e.g. matrix multiplication) constrains your choice of software and hardware (i.e., the GPU-friendliness vs CPU-friendliness of machine learning)
 The impact your choice of programming languages to learn (e.g. C++ vs Python or JavaScript or R) has on the tools and libraries you later use
 Which data sets to use to train your learning models
 Which neural networks are optimal for making predictions on inputs of certain sorts, e.g., videos vs static images vs speech vs text
 As with distributed systems and decentralized blockchains, the fit between what problems you want to solve and what combination of solutions (per above) to employ
 Tidbits
 Lex Fridman’s podcast, Artificial Intelligence Podcast, features interviews with the above-mentioned Pieter Abbeel and Max Tegmart as well as many others in the ML and AI spaces
 The subject of generative adversarial networks (GANs) is apparently a hot area of research
 3Blue1Brown’s video “But what IS a Neural Network?” is the best video I’ve yet seen on perceptrons and the structure & purpose of neural networks
 “Deep Learning Cars” is a video by Samuel Artz that simulates, in 2D, cars on a race course. In the video’s description is a link to the source code for the simulation
 Toronto computer hardware company Xanadu is working on advanced AI and “photonic quantum computing” chips to enable quantum applications of machine learning
 For some excellent visuals and explanations of various neural network architectures, see the articles “The Neural Network Zoo Prequel Cells and Layers” and “The Neural Network Zoo” by AI research company The Asimov Institute. You can also read Andrew Tchircoff’s “The mostly complete chart of Neural Networks, explained” at Towards Data Science
 Some neural networks can be run inside phone applications and are bundled in a file with special extensions (e.g., .mlmodel for apps running MLModel on the iPhone or .tflite for apps running TensorFlow Lite on Android devices). So, by example, iPhone developers can integrate machine learning models into their apps by using Apple’s Core ML framework, the Core ML API, and the MLModel class. The key point is that some neural networks work with the limited resources of a CPU on something like an iPhone, which is amazing, and perhaps a stepping stone to neural networks running on even lower-power IoT devices in the future.
 Amazon AWS Machine Learning currently supports three types of machine learning models, namely binary classification, multiclass classification, and regression, each of which is ideal for making different types of predictions
 Game theory; complexity theory; statistics of many kinds, as well as major statistical theories (e.g., Bayesian) and related techniques (e.g., regression); linear algebra, and other academic disciplines appear to be important layers to the work of artificial intelligence. That is very interesting, something machine learning technologies appear to share with decentralized systems (blockchains) to work, they must draw on principles from economics, statistics, computer science, and mathematics
 Some universities offer not only free online courses but also paid certificate programs, such as MIT Online’s professional education and Stanford Online’s graduate education, in various sub-areas of machine learning
 For a short technical introduction to prior distributions, likelihood functions, & posterior probabilities in the software Stata, see Chuck Huber’s video “Introduction to Bayesian statistics, part 1 The basic concepts”
 The MIT Sloan Management Review article “The Machine Learning Race Is Really a Data Race” by Megan Beck and Barry Libert raises good questions about the importance of unique data to train machine learning models used in commercial applications
 Tools
 Amazon Machine Learning
 Azure Machine Learning Studio
 Caffe & Caffe2
 Colaboratory
 DataCamp
 Google Cloud AI & Machine Learning
 PyTorch
 TensorFlow
 Supplemental Notes on Tools
 Colaboratory, a free Jupyter notebook environment that requires no setup and runs entirely in the cloud, has a lot to love, but in particular comes with an interactive notebook version of Jake VanderPlas’s book, Python Data Science Handbook Essential Tools for Working with Data, and links to the self-paced website, Machine Learning Crash Course by Google
 Google Cloud Platform has excellent self-paced material in its Google Cloud Training Platform, which includes labs through Qwiklabs and three Data and Machine Learning learning tracks one for data analysts, one for data engineering, and one for data scientists
 For one opinion on PyTorch vs TensorFlow, see “Tensorflow or PyTorch  The force is strong with which one?” by Yashwardhan Jain
 Quantum Machine Learning bridges the gap between abstract developments in quantum computing and the applied research on machine learning. Paring down the complexity of the disciplines involved, it focuses on providing a synthesis that explains the most important machine learning algorithms in a quantum framework. Theoretical advances in quantum computing are hard to follow for computer scientists, and sometimes even for researchers involved in the field. The lack of a step-by-step guide hampers the broader understanding of this emergent interdisciplinary body of research.
 Quantum Machine Learning sets the scene for a deeper understanding of the subject for readers of different backgrounds. The author has carefully constructed a clear comparison of classical learning algorithms and their quantum counterparts, thus making differences in computational complexity and learning performance apparent. This book synthesizes of a broad array of research into a manageable and concise presentation, with practical examples and applications.
 Bridges the gap between abstract developments in quantum computing with the applied research on machine learning
 Provides the theoretical minimum of machine learning, quantum mechanics, and quantum computing
 Gives step-by-step guidance to a broader understanding of this emergent interdisciplinary body of research
 You can edit this line in _config.yml. It will appear in your document
 head meta (for Google search results) and in your feed.xml site
 description.
copyright:          '2020 Quantum Hack'
credits:            ''

# ----------------------- #
#    Jekyll & Plugins     #
# ----------------------- #

include:
  - .htaccess
  - _pages

sass:
  sass_dir:         _sass


# Build settings
markdown:           kramdown
highlighter:        rouge
permalink:          pretty
lsi:                false
excerpt_separator:  "\n\n"
incremental:        false



# Markdown Processing
kramdown:
  input:            GFM
  hard_wrap:        false
  auto_ids:         true
  footnote_nr:      1
  entity_output:    as_char
  toc_levels:       1..6
  smart_quotes:     lsquo,rsquo,ldquo,rdquo
  enable_coderay:   false
  parse_block_html: true # default for kramdown is false. This will enable using Markdown links

#plugins:
#  - jekyll-feed
#  - jekyll-seo-tag
# ----------------------- #
#   3rd Party Settings    #
# ----------------------- #

social:
  - title:          twitter
    url:            https://twitter.com/QuantumhackM
  - title:          github
    url:            https://github.com/quantumhack
  - title:          linkedin
    url:            https://www.linkedin.com/in/quantumhack-ml-a1b2081a3
